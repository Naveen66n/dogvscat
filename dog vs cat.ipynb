{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5cb9c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"tongpython/cat-and-dog\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0b6eac63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73591388",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = \"C:\\\\Users\\\\naveenkumar\\\\.cache\\\\kagglehub\\\\datasets\\\\tongpython\\\\cat-and-dog\\\\versions\\\\1\\\\training_set\\\\training_set\"\n",
    "test_dir = \"C:\\\\Users\\\\naveenkumar\\\\.cache\\\\kagglehub\\\\datasets\\\\tongpython\\\\cat-and-dog\\\\versions\\\\1\\\\test_set\\\\test_set\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a3b705f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Data Generator \n",
    "train_datagen = ImageDataGenerator( #ImageDataGenerator preprocesses images before feeding them into the model.\n",
    "    rescale=1./255,         # Converts pixel values from (0-255) to (0-1).\n",
    "    shear_range=0.2,        # Applies a shear transformation (slants the image along the x/y axis).\n",
    "    zoom_range=0.2,         # Randomly zooms in or out by up to 20%.\n",
    "    horizontal_flip=True    #Randomly flips images horizontally.\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)  # Only rescales the pixel values (no augmentation).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11899e84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8005 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Load training data\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(128, 128),  # Resize all images to 128x128\n",
    "    batch_size=32,\n",
    "    class_mode='binary'      # Binary classification (cat vs. dog)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1760af0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2023 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Load test data\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(128, 128),\n",
    "    batch_size=32,\n",
    "    class_mode='binary'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ba44af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Define input layer separately #sequentially, meaning each layer's output becomes the next layer's input.\n",
    "model = keras.Sequential([\n",
    "    layers.Input(shape=(128, 128, 3)),  # Define input shape explicitly\n",
    "\n",
    "    layers.Conv2D(32, (3,3), activation='relu'),#This is a convolutional layer with 32 filters of size 3×3\n",
    "    layers.MaxPooling2D(2,2),\n",
    "\n",
    "    layers.Conv2D(64, (3,3), activation='relu'),#Adds a second convolutional layer with 64 filters (more filters mean capturing more complex features).\n",
    "    layers.MaxPooling2D(2,2),\n",
    "\n",
    "    layers.Conv2D(128, (3,3), activation='relu'),#Third convolutional layer with 128 filters to learn even more detailed features.\n",
    "    layers.MaxPooling2D(2,2),\n",
    "\n",
    "    layers.Flatten(),#Converts the multi-dimensional feature maps into a 1D vector\n",
    "    layers.Dense(512, activation='relu'),#A dense (fully connected) layer with 512 neurons.\n",
    "    layers.Dense(1, activation='sigmoid')  #This output layer has 1 neuron because it is a binary classification problem (cat vs. dog).\n",
    "\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9674d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile Model\n",
    "model.compile(\n",
    "    loss='binary_crossentropy',#The loss function measures how well the model's predictions match the actual labels\n",
    "    optimizer='adam',#Adam  is an optimization algorithm that updates the model's weights during training.\n",
    "    metrics=['accuracy']#Tracks the percentage of correct predictions.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40816d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summarymary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d619f979",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\naveenkumar\\anaconda3\\lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.5365 - loss: 0.7061"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\naveenkumar\\anaconda3\\lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m511s\u001b[0m 2s/step - accuracy: 0.5367 - loss: 0.7059 - val_accuracy: 0.6653 - val_loss: 0.6155\n",
      "Epoch 2/10\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m365s\u001b[0m 1s/step - accuracy: 0.6520 - loss: 0.6207 - val_accuracy: 0.7054 - val_loss: 0.5534\n",
      "Epoch 3/10\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m327s\u001b[0m 1s/step - accuracy: 0.6931 - loss: 0.5787 - val_accuracy: 0.7355 - val_loss: 0.5320\n",
      "Epoch 4/10\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m328s\u001b[0m 1s/step - accuracy: 0.7286 - loss: 0.5436 - val_accuracy: 0.7583 - val_loss: 0.4994\n",
      "Epoch 5/10\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m268s\u001b[0m 1s/step - accuracy: 0.7575 - loss: 0.5053 - val_accuracy: 0.7489 - val_loss: 0.5292\n",
      "Epoch 6/10\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m289s\u001b[0m 1s/step - accuracy: 0.7712 - loss: 0.4662 - val_accuracy: 0.7687 - val_loss: 0.4866\n",
      "Epoch 7/10\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m291s\u001b[0m 1s/step - accuracy: 0.7873 - loss: 0.4475 - val_accuracy: 0.7652 - val_loss: 0.4806\n",
      "Epoch 8/10\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m254s\u001b[0m 991ms/step - accuracy: 0.7922 - loss: 0.4306 - val_accuracy: 0.7944 - val_loss: 0.4494\n",
      "Epoch 9/10\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m237s\u001b[0m 941ms/step - accuracy: 0.8111 - loss: 0.4172 - val_accuracy: 0.7939 - val_loss: 0.4358\n",
      "Epoch 10/10\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m266s\u001b[0m 959ms/step - accuracy: 0.8271 - loss: 0.3834 - val_accuracy: 0.7944 - val_loss: 0.4557\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x211247d5a50>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train Model\n",
    "model.fit(train_generator, epochs=10, validation_data=test_generator)\n",
    "#train_generator - Feeds training images and labels to the model.\n",
    "#epochs=10 - Model trains for 10 complete passes over data.\n",
    "#validation_data=test_generator - Evaluates performance on unseen data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4f05bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loss → Measures how far the predictions are from actual values.\n",
    "#Goal → Minimize loss while maximizing accuracy.\n",
    "\n",
    "#Training Loss improves faster (direct feedback from optimizer).\n",
    "#Validation Loss should also decrease (indicates generalization).\n",
    "#If validation loss increases while training loss decreases → Overfitting!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2f237357",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training complete and saved as 'cat_dog_classifier.h5'.\n"
     ]
    }
   ],
   "source": [
    "model.save(\"cat_dog_classifier.h5\")\n",
    "\n",
    "print(\"Model training complete and saved as 'cat_dog_classifier.h5'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8f4bfe0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "# Load trained model\n",
    "model = load_model(\"cat_dog_classifier.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bd6145aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "\n",
    "img_path = r\"C:\\Users\\naveenkumar\\.cache\\kagglehub\\datasets\\tongpython\\cat-and-dog\\versions\\1\\test_set\\test_set\\dogs\\dog.4259.jpg\"\n",
    "img = image.load_img(img_path, target_size=(128, 128))\n",
    "img_array = image.img_to_array(img) / 255.0\n",
    "img_array = np.expand_dims(img_array, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "48b13686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 525ms/step\n",
      "Dog\n"
     ]
    }
   ],
   "source": [
    "# Predict\n",
    "prediction = model.predict(img_array)\n",
    "print(\"Dog\" if prediction[0][0] > 0.5 else \"Cat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335c3a2f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
